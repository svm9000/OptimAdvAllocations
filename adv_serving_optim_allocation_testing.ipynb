{"cells":[{"cell_type":"markdown","metadata":{"id":"jUIj-tV35Smv"},"source":["# Testing ideas for distributing geogroup applications to geokeys using integer values"]},{"cell_type":"markdown","metadata":{"id":"gWHw7Eh4Tev6"},"source":["\n","Assume we have an optimised set of ads served (impression) to the user on a given device at the **(days,campaign,geogroups)** level - how do we assign this at the **postcode (geokey)** level. The geogroup can be thought of as a **Postcode Sector**.\n","\n","Notebook contains some ideas for distributing geogroup (Postal sector) to geokeys (postcode) as integer values. Essentially an **integer optimisation problem**.\n","\n","Some assumptions:\n","\n","* There are around **1.4 million postcode geokeys**\n","* Around **10k** postal sectors (geo groups).\n","* We cannot have **fractional impressions**, so have consider approaches such as the **D'hondt method**.\n"]},{"cell_type":"markdown","metadata":{"id":"90HL8tX_8kDJ"},"source":["# Hagenbach-Bischoff quota (Adapted D'Hondt method)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"pPfnhDgia59t"},"outputs":[],"source":["import numpy as np \n","#initial implementation taken from the https://stackoverflow.com/questions/16226991/allocate-an-array-of-integers-proportionally-compensating-for-rounding-errors\n","#and adapted to suit example above. \n","def hbischoff_distribute_geogroup_geokey(total_geogroup_impressions: int,target:np.ndarray,geokey_weights:np.ndarray)-> np.ndarray:\n","    \"\"\"assign total geogroup impressions proportionally to geokeys using Hagenbach-Bischoff quota\n","    :total_geogroup_impressions (int): Total number of impressions at the geogroup level to distribute\n","    :target(np.ndarray): numpy array with the geogroup to geokey target\n","    :geokey_weights (np.ndarray): numpy array of geokey weights\n","    :return: a numpy array of integer impressions for the geokey level breakdown\n","    \"\"\"\n","\n","    assert np.sum(geokey_weights)!=0, f\"issue with geokey_weights sum to 0: {geokey_weights}\"\n","\n","    #replace any nan values in the weights\n","    geokey_weights[np.isnan(geokey_weights)] = 0\n","    #only use the targeted geokeys\n","    geokey_weights = target*geokey_weights\n","    #normalise the weights\n","    geokey_weights /= geokey_weights.sum()\n","    \n","\n","    quota=sum(geokey_weights)/(1.+total_geogroup_impressions) #force float\n","    frac=[geoweight/quota for geoweight in geokey_weights]\n","    #print(\"v1 frac = \",frac)\n","\n","    res=[int(f) for f in frac]\n","    #print(\"res v1 \",res)\n","    n=total_geogroup_impressions-sum(res) #number of geokeys remaining to allocate\n","    #print(\"type n = \",n)\n","\n","    if n==0: return res #done\n","    if n<0: return [min(x,total_geogroup_impressions) for x in res] #to handle case where geokey_weights=[0,0,..,1,0,...,0]\n","\n","    #distribute the remaining impressions to the geokeys with the largest remainder\n","    remainders=[ai-bi for ai,bi in zip(frac,res)]\n","\n","    limit=sorted(remainders,reverse=True)[n-1]\n","    #assign the remainder to the geokeys with the largest remainder \n","    for i,r in enumerate(remainders):\n","        if r>=limit:\n","            res[i]+=1\n","            n-=1 # attempt to handle perfect equality\n","            if n==0: return res #done\n","    raise #should never happen"]},{"cell_type":"markdown","metadata":{"id":"7037sHfRNOrj"},"source":["# Hagenbach-Bischoff quota (Adapted D'Hondt method) - Improved implementation"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"HokJsGFPNPLi"},"outputs":[],"source":["import numpy as np \n","#initial implementation taken from the https://stackoverflow.com/questions/16226991/allocate-an-array-of-integers-proportionally-compensating-for-rounding-errors\n","#and adapted to suit example above. \n","def hbischoff_distribute_geogroup_geokey_v2(total_geogroup_impressions: int,target:np.ndarray,geokey_weights:np.ndarray)-> np.ndarray:\n","    \"\"\"\n","    assign total geogroup impressions proportionally to geokeys using Hagenbach-Bischoff quota\n","    :total_geogroup_impressions (int): Total number of impressions at the geogroup level to distribute\n","    :target(np.ndarray): numpy array with the geogroup to geokey target\n","    :geokey_weights (np.ndarray): numpy array of geokey weights\n","    :return: a numpy array of integer impressions for the geokey level breakdown\n","    \"\"\"\n","\n","    assert np.sum(geokey_weights)!=0, f\"issue with geokey_weights sum to 0: {geokey_weights}\"\n","\n","    #replace any nan values in the weights\n","    geokey_weights[np.isnan(geokey_weights)] = 0\n","    #only use the targeted geokeys\n","    geokey_weights = target*geokey_weights\n","    #normalise the weights\n","    geokey_weights /= geokey_weights.sum()\n","    \n","    quota = sum(geokey_weights)/(1+total_geogroup_impressions)\n","    frac = [geoweight/quota for geoweight in geokey_weights]\n","    res = np.floor(frac).astype(int)\n","    #print(\"v2 frac = \",frac)\n","    #print(\"type = \",type(frac))\n","    #print(\"res v2= \",res,\" \",frac)\n","    n=total_geogroup_impressions-sum(res) #number of geokeys remaining to allocate\n","    #print(\"type n v2= \",n)\n","\n","    if n==0: return res #done\n","    if n<0: return [min(x,total_geogroup_impressions) for x in res] #to handle case where geokey_weights=[0,0,..,1,0,...,0]\n","\n","    #distribute the remaining impressions to the geokeys with the largest remainder\n","    remainders = frac - res\n","    \n","    #sort by the largest limit\n","    limit = remainders[np.argsort(remainders)[::-1][n-1]]\n","\n","    #assign the remainder to the geokeys with the largest remainder \n","    for i,r in enumerate(remainders):\n","        if r>=limit:\n","            res[i]+=1\n","            n-=1 # attempt to handle perfect equality\n","            if n==0: return res #done\n","    raise #should never happen\n","\n","def hbischoff_distribute_geogroup_base(total_geogroup_impressions: int,geokey_weights:np.ndarray)-> np.ndarray:\n","    \"\"\"assign total geogroup impressions proportionally to geokeys using Hagenbach-Bischoff quota\n","    :total_geogroup_impressions (int): Total number of impressions at the geogroup level to distribute\n","    :target(np.ndarray): numpy array with the geogroup to geokey target\n","    :geokey_weights (np.ndarray): numpy array of geokey weights\n","    :return: a numpy array of integer impressions for the geokey level breakdown\n","    \"\"\"\n","\n","    assert np.sum(geokey_weights)!=0, f\"issue with geokey_weights sum to 0: {geokey_weights}\"\n","\n","\n","    \n","    quota = sum(geokey_weights)/(1+total_geogroup_impressions)\n","    frac = [geoweight/quota for geoweight in geokey_weights]\n","    res = np.floor(frac).astype(int)\n","\n","    n=total_geogroup_impressions-sum(res) #number of geokeys remaining to allocate\n","\n","    if n==0: return res #done\n","    if n<0: return [min(x,total_geogroup_impressions) for x in res] #to handle case where geokey_weights=[0,0,..,1,0,...,0]\n","\n","    #distribute the remaining impressions to the geokeys with the largest remainder\n","    remainders = frac - res\n","    \n","    #sort by the largest limit\n","    limit = remainders[np.argsort(remainders)[::-1][n-1]]\n","\n","    #assign the remainder to the geokeys with the largest remainder \n","    for i,r in enumerate(remainders):\n","        if r>=limit:\n","            res[i]+=1\n","            n-=1 # attempt to handle perfect equality\n","            if n==0: return res #done\n","    raise #should never happen\n"]},{"cell_type":"markdown","metadata":{"id":"I3OflhFF4BPa"},"source":["# Adapted D'Hondt method for running with geogroup to geokey target and larger impressions"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"R_OtpO_A4ATj"},"outputs":[],"source":["import numpy as np \n","\n","def dhondt_distribute_geogroup_geokey( total_geogroup_impressions: int\n","                               ,target:np.ndarray\n","                               ,geokey_weights:np.ndarray\n","                               ,block_ratio:int=100)-> np.ndarray:\n","  \"\"\"\n","  assign total geogroup impressions proportionally to geokeys using D'Hondt method\n","  :total_geogroup_impressions (int): Total number of impressions at the geogroup level to distribute\n","  :target(np.ndarray): numpy array with the geogroup to geokey target\n","  :geokey_weights (np.ndarray): numpy array of geokey weights\n","  :block_ratio (int): used to find the number of block impressions to subtract from the total \n","   total_geogroup_impressions for each assignment to geokeys. Smaller values often lead to faster\n","   execution with less precision than larger values.\n","  :return: a numpy array of integer impressions for the geokey level breakdown\n","  \"\"\"\n","\n","  assert np.sum(geokey_weights)!=0, f\"issue with geokey_weights sum to 0: {geokey_weights}\"\n","\n","  #replace any nan values in the weights\n","  geokey_weights[np.isnan(geokey_weights)] = 0\n","  #only use the targeted geokeys\n","  geokey_weights = target*geokey_weights\n","\n","  #normalise geokey weights so they add to 100%\n","  geokey_weights /=geokey_weights.sum()\n","  #print(geokey_weights)\n","\n","\n","  number_geokeys = len(geokey_weights)\n","  final_allocations = np.zeros(number_geokeys,dtype=np.int64)\n","\n","  #the number of block impressions to subtract from the total on each round.\n","  block_allocation = np.max((1,int(total_geogroup_impressions/block_ratio)))\n","  #print(\"block_allocation = \",block_allocation)\n","  left_impressions = total_geogroup_impressions\n","\n","  while left_impressions > 0:\n","    \n","    quota= geokey_weights/(final_allocations+block_allocation)\n","\n","    max_index = np.argmax(quota)\n","\n","    #max_index = np.argsort(quota)[int((number_geokeys)/3)]\n","    final_allocations[max_index] +=block_allocation\n","\n","    left_impressions -= block_allocation\n","\n","    #if we have any excess truncate the last geokey allocation\n","    if left_impressions<0:\n","      final_allocations[max_index] += left_impressions\n","\n","  #if there are no allocation for a geokey with positive weight, then \n","  #take from the largest geokey and redistribute\n","  check_zero_alloc = np.where(final_allocations==0)\n","  #print(\"check_zero_alloc=\", check_zero_alloc)\n","  #print(\"check_zero_alloc=\", check_zero_alloc[0])\n","\n","  if np.any(check_zero_alloc):\n","    for i in range(len(check_zero_alloc[0])):\n","      #if the rescaled geokey weights are positive and the final allocation is 0 we re-distribute\n","      #impressions from the largest geokey to the smallest ones.\n","      if geokey_weights[check_zero_alloc[0][i]] >0:\n","        #find the expected number of integer impressions for the zero allocated geokey\n","        redistribute_imp = np.round(total_geogroup_impressions * geokey_weights[check_zero_alloc[0][i]])\n","        #subtract the number of impressions that need to be redistributed from the largest geokey\n","        final_allocations[np.argmax(final_allocations)] -=  redistribute_imp\n","        #redistribute the impressions to the zero allocated geokey\n","        final_allocations[check_zero_alloc[0][i]]= redistribute_imp\n","\n","    \n","  return final_allocations\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ekSvyGJ3STqo"},"source":["# CVXPY solver + adapted d'hondt "]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1644947932672,"user":{"displayName":"Siva Murugiah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18304063581860340883"},"user_tz":0},"id":"9RDH-dpWXiXg","outputId":"c90aa5bf-79ee-4651-da0f-8d83e0538efb"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0.]]\n","check output reconstructed out =  [332962.0001035  665926.99992964 332962.0001035  665926.99992964\n"," 998886.99999048 -32826.99995133]\n","check output reconstructed sum out =  2963838.000105447\n","check output reconstructed weights =  1.0000000000000002\n"]}],"source":["from os import truncate\n","import cvxpy as cp\n","\n","def cvxpy_distribute_geogroup_geokey(total_geogroup_impressions: int\n","          ,target:np.ndarray\n","          ,geokey_weights:np.ndarray\n","          ,rounding_limit_fix:bool =True):\n","    \"\"\"\n","    :total_geogroup_impressions (int): Total number of impressions at the geogroup level to distribute\n","    :target(np.ndarray): numpy array with the geogroup to geokey target\n","    :geokey_weights (np.ndarray): numpy array of geokey weights\n","    :rounding_limit_fix (bool): apply the adapted d'hondts method to fix rounding issues for the limits b\n","    :return: a numpy array of integer impressions for the geokey level breakdown\n","    \"\"\"\n","    num_geokeys = len(geokey_weights)\n","\n","    x = cp.Variable(num_geokeys, integer=True)\n","\n","    c = cp.Constant(geokey_weights.astype(np.float64))\n","\n","    #np.ones((num_geokeys,1))\n","    A = np.eye(num_geokeys)\n","    A = np.vstack((A,np.expand_dims(1-target,0)))\n","\n","    if rounding_limit_fix:\n","      b =  hbischoff_distribute_geogroup_base(total_geogroup_impressions,geokey_weights)\n","    else:\n","      b = total_geogroup_impressions * geokey_weights\n","\n","    b =  np.hstack((b,0))\n","    #print(\"b=\",b)\n","    objective = cp.Maximize(c.T@x)\n","    \n","    constraints = [A @ x <= b]\n","\n","    problem = cp.Problem(objective, constraints)\n","\n","    problem.solve(verbose=False,solver='ECOS_BB')\n","\n","    if x.value is None:\n","        return None, None\n","    \n","    return x.value\n","\n","\n","total_geogroup_impressions = 3000000\n","target  = np.array([1,1,1,1,1,1])\n","\n","geokey_weights  = np.array([0.1,0.2,0.1,0.2,0.3,0.001])\n","\n","print(np.vstack((np.eye(6), np.expand_dims(np.array(1-target),axis=0))))\n","\n","out = cvxpy_distribute_geogroup_geokey(total_geogroup_impressions\n","                                 ,target\n","                                 ,geokey_weights\n","                                 ,True)\n","\n","print(\"check output reconstructed out = \", out)\n","\n","print(\"check output reconstructed sum out = \", np.sum(out))\n","\n","print(\"check output reconstructed weights = \", np.sum(out/sum(out)))"]},{"cell_type":"markdown","metadata":{"id":"99jCqZrl13NY"},"source":["# Test on dummy data"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1644947184170,"user":{"displayName":"Siva Murugiah","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18304063581860340883"},"user_tz":0},"id":"EB1YxeP812go","outputId":"aff36b43-4d2e-425a-c710-1de68c076ffc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Check to see final hdondt allocations sum to the total geogroup impressions =  True\n","Check to see final hbischoff allocations sum to the total geogroup impressions =  True\n","Check to see if the geokey_weights sum to 1 =  1.0\n","Check the theoretical geokey weights =  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n"," 0.11111111 0.11111111 0.11111111]\n","Check the allocated geokey weights dhondt =  [0.12 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11]\n","Check the allocated geokey dhondt =  [1080  990  990  990  990  990  990  990  990]\n","Check the allocated geokey weights hbischoff =  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n"," 0.11111111 0.11111111 0.11111111]\n","Check the allocated geokey hbischoff =  [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n","Check the allocated geokey hbischoff sum =  9000\n","Check the allocated geokey weights cvxpy =  [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n"," 0.11111111 0.11111111 0.11111111]\n","Check the allocated geokey cvxpy =  [999.99999995 999.99999995 999.99999995 999.99999995 999.99999995\n"," 999.99999995 999.99999995 999.99999995 999.99999995]\n","Check the allocated geokey cvxpy sum =  8999.999999506124\n"]}],"source":["#Assumed total geogroup impressions that need to be distributed\n","total_geogroup_impressions = 3000000\n","total_geogroup_impressions = 9000  \n","#Assume we target all geokeys\n","target  = np.array([1]*9)\n","#Assume weight for the distribution across geokeys\n","#geokey_weights  = np.array([0.1,0.2,0.1,0.2,0.3,0.1])\n","#geokey_weights  = np.array([0.1]*4 +[0.599]+[0.001])\n","#geokey_weights  = np.array([1/6]*6)\n","geokey_weights  = np.array([1/9]*9,dtype=np.float64)\n","\n","#print(\"check  = \" , geokey_weights*(total_geogroup_impressions+1))\n","#print(\"check  = \" , geokey_weights/(sum(geokey_weights)/(1+total_geogroup_impressions)))\n","#print(\"check  = \" ,   [geoweight/(sum(geokey_weights)/(1+total_geogroup_impressions)) for geoweight in geokey_weights])\n","#print(\"check =\",np.divide(geokey_weights,np.divide(sum(geokey_weights),(1+total_geogroup_impressions))))\n","\n","#d'hondt method\n","final_allocations_dhondt = dhondt_distribute_geogroup_geokey(total_geogroup_impressions\n","                                                    ,target\n","                                                    ,geokey_weights)\n","\n","#Hbischof method\n","final_allocations_hbischoff = hbischoff_distribute_geogroup_geokey(total_geogroup_impressions\n","                                                    ,target\n","                                                    ,geokey_weights)\n","\n","\n","#cvxpy method\n","final_allocations_cvxpy = cvxpy_distribute_geogroup_geokey(total_geogroup_impressions\n","                                                    ,target\n","                                                    ,geokey_weights\n","                                                    ,True)\n","\n","\n","print(\"Check to see final hdondt allocations sum to the total geogroup impressions = \",np.sum(final_allocations_dhondt)==total_geogroup_impressions)\n","print(\"Check to see final hbischoff allocations sum to the total geogroup impressions = \",np.sum(final_allocations_hbischoff)==total_geogroup_impressions)\n","print(\"Check to see if the geokey_weights sum to 1 = \",np.sum(geokey_weights))\n","print(\"Check the theoretical geokey weights = \",geokey_weights)\n","print(\"Check the allocated geokey weights dhondt = \", (final_allocations_dhondt/np.sum(final_allocations_dhondt)))\n","print(\"Check the allocated geokey dhondt = \", final_allocations_dhondt)\n","print(\"Check the allocated geokey weights hbischoff = \", (final_allocations_hbischoff/np.sum(final_allocations_hbischoff)))\n","print(\"Check the allocated geokey hbischoff = \", final_allocations_hbischoff)\n","print(\"Check the allocated geokey hbischoff sum = \", np.sum(final_allocations_hbischoff))\n","print(\"Check the allocated geokey weights cvxpy = \", (final_allocations_cvxpy/np.sum(final_allocations_cvxpy)))\n","print(\"Check the allocated geokey cvxpy = \", final_allocations_cvxpy)\n","print(\"Check the allocated geokey cvxpy sum = \", np.sum(final_allocations_cvxpy))\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNlsO7xLcAk18Hic7YDRQML","collapsed_sections":[],"name":"redistribution_ideas_with_cvxpy.ipynb","provenance":[{"file_id":"1np-mu9GYvBvqP2z68BYxMR3F9Xq-XGzQ","timestamp":1644856072582}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
